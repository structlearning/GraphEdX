{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import librariesImport\n",
    "# import gedlibpy\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.utils import from_networkx\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "from multiprocessing import Pool\n",
    "from matplotlib import pyplot as plt\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f107c0aa5b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_folder = \"./data_wo_node_attr/\"\n",
    "if not os.path.exists(dest_folder):\n",
    "    os.makedirs(dest_folder)\n",
    "    \n",
    "# Filter graphs with more than max_num_nodes nodes\n",
    "max_num_nodes = 20\n",
    "NUM_WORKER = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Methods for filtering graphs\n",
    "\n",
    "class TimeoutError(Exception):\n",
    "    pass\n",
    "\n",
    "def handler(signum, frame):\n",
    "    raise TimeoutError()\n",
    "\n",
    "def set_x(data_obj):\n",
    "    data_obj.x = torch.ones(data_obj.num_nodes, 1)\n",
    "    return data_obj\n",
    "\n",
    "def node_match(n1, n2):\n",
    "    return np.argmax(n1['x']) == np.argmax(n2['x'])\n",
    "\n",
    "def node_match_multi_hot(n1, n2):\n",
    "    return np.array_equal(n1['x'], n2['x'])\n",
    "\n",
    "def get_unique_graphs_using_nx(nx_graphs, timeout_duration = 15, node_match_func = None, max_unique_cnt = None):\n",
    "    # Filter Isomorphic graphs using nx.is_isomorphic\n",
    "    unique_graphs = [nx_graphs[0]]\n",
    "    if max_unique_cnt == None:\n",
    "        max_unique_cnt = len(nx_graphs)\n",
    "\n",
    "    if node_match_func == None:\n",
    "        node_match_func = node_match\n",
    "    \n",
    "    signal.signal(signal.SIGALRM, handler) \n",
    "\n",
    "    print(\"Filtering isomorphic graphs...\")\n",
    "    for i in tqdm(range(1, len(nx_graphs))):\n",
    "        unique = True\n",
    "        if(len(unique_graphs) >= max_unique_cnt):\n",
    "            break\n",
    "        for j in range(len(unique_graphs)):\n",
    "            g1 = nx_graphs[i]\n",
    "            g2 = unique_graphs[j]\n",
    "            if g1.number_of_nodes() > g2.number_of_nodes():\n",
    "                g1, g2 = g2, g1\n",
    "\n",
    "            signal.alarm(timeout_duration)\n",
    "            try:\n",
    "                if nx.is_isomorphic(g1, g2, node_match=node_match):\n",
    "                    #print(\"Graph \", i, \" is isomorphic to graph \", j)\n",
    "                    unique = False\n",
    "                    break\n",
    "            except TimeoutError:\n",
    "                print(f\"Timeout for graph {i}\")\n",
    "                unique = False\n",
    "                break\n",
    "            finally:\n",
    "                signal.alarm(0)\n",
    "        if unique:\n",
    "            #print(\"Including graph \", i, \" in unique_graphs\")\n",
    "            unique_graphs.append(nx_graphs[i])\n",
    "    print(f\"Total number of Unique graphs: {len(unique_graphs)}\")\n",
    "    return unique_graphs\n",
    "\n",
    "\n",
    "def split_and_dump_graphs(nx_graphs, data_path = None, DATASET = \"\"):\n",
    "    print(\"Splitting and dumping graphs...\")\n",
    "    if data_path == None:\n",
    "        print(\"ERROR: Data path not provided\")\n",
    "        return\n",
    "    \n",
    "    random.seed(0)\n",
    "    random.shuffle(nx_graphs)    # Shuffle the list of graphs\n",
    "    train_size = int(0.6*len(nx_graphs))\n",
    "    val_size = int(0.2*len(nx_graphs))\n",
    "    test_size = len(nx_graphs) - train_size - val_size\n",
    "\n",
    "    train_graphs = nx_graphs[:train_size]\n",
    "    val_graphs = nx_graphs[train_size:train_size+val_size]\n",
    "    test_graphs = nx_graphs[train_size+val_size:]\n",
    "    print(f\"Train: {len(train_graphs)}, Val: {len(val_graphs)}, Test: {len(test_graphs)}\")\n",
    "\n",
    "\n",
    "    # Dump Non-isomorphic Graphs \n",
    "    train_data = []\n",
    "    for graph in train_graphs:\n",
    "        data = from_networkx(graph, group_node_attrs = ['x'])\n",
    "        train_data.append(data)\n",
    "    \n",
    "    print(\"sample:\", train_data[0])\n",
    "    torch.save(train_data, data_path + \"train.pt\")\n",
    "    print(f\"saved {DATASET} into {data_path}train.pt\")\n",
    "\n",
    "    val_data = []\n",
    "    for graph in val_graphs:\n",
    "        data = from_networkx(graph, group_node_attrs = ['x'])\n",
    "        val_data.append(data)\n",
    "    #print(val_data[0].x)\n",
    "    torch.save(val_data, data_path + \"val.pt\")\n",
    "    print(f\"saved {DATASET} into {data_path}val.pt\")\n",
    "\n",
    "    test_data = []\n",
    "    for graph in test_graphs:\n",
    "        data = from_networkx(graph, group_node_attrs = ['x'])\n",
    "        test_data.append(data)\n",
    "    torch.save(test_data, data_path + \"test.pt\")\n",
    "    print(f\"saved {DATASET} into {data_path}test.pt\")\n",
    "\n",
    "\n",
    "def check_leakage(data_path, node_match_fun = None, full_check = False):\n",
    "    print(\"Checking for leakage...\")\n",
    "    print(\"loading saved splits from \", data_path)\n",
    "    train_data = torch.load(data_path + \"/train.pt\")\n",
    "    val_data = torch.load(data_path + \"/val.pt\")\n",
    "    test_data = torch.load(data_path + \"/test.pt\")\n",
    "\n",
    "    train_nx = list(map(functools.partial(to_networkx, to_undirected=True, node_attrs = ['x']), train_data))\n",
    "    val_nx = list(map(functools.partial(to_networkx, to_undirected=True, node_attrs = ['x']), val_data))\n",
    "    test_nx = list(map(functools.partial(to_networkx, to_undirected=True, node_attrs = ['x']), test_data))\n",
    "    \n",
    "    print(\"Number of graphs in train: \", len(train_nx), \" Val: \", len(val_nx), \" Test: \", len(test_nx))\n",
    "\n",
    "    if node_match_fun == None:\n",
    "        node_match_fun = node_match\n",
    "\n",
    "    if full_check:\n",
    "        cnt = 0\n",
    "        for i in tqdm(range(len(train_nx))):\n",
    "            for j in range(len(train_nx)):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                if nx.is_isomorphic(train_nx[i], train_nx[j], node_match=node_match_fun):\n",
    "                    #print(\"Isomorphic graph found between train and val\")\n",
    "                    cnt += 1\n",
    "                    break\n",
    "        print(\"Number of duplicate inside train: \", cnt)\n",
    "        \n",
    "        cnt = 0\n",
    "        for i in tqdm(range(len(val_nx))):\n",
    "            for j in range(len(val_nx)):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                if nx.is_isomorphic(val_nx[i], val_nx[j], node_match=node_match_fun):\n",
    "                    #print(\"Isomorphic graph found between train and val\")\n",
    "                    cnt += 1\n",
    "                    break\n",
    "        print(\"Number of duplicates inside val:\", cnt)\n",
    "        \n",
    "        cnt = 0\n",
    "        for i in tqdm(range(len(test_nx))):\n",
    "            for j in range(len(test_nx)):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                if nx.is_isomorphic(test_nx[i], test_nx[j], node_match=node_match_fun):\n",
    "                    #print(\"Isomorphic graph found between train and val\")\n",
    "                    cnt += 1\n",
    "                    break\n",
    "        print(\"Number of duplicates inside test:\", cnt)\n",
    "\n",
    "\n",
    "    cnt = 0\n",
    "    for val_g in tqdm(val_nx):\n",
    "        for train_g in train_nx:\n",
    "            if nx.is_isomorphic(train_g, val_g, node_match=node_match_fun):\n",
    "                #print(\"Isomorphic graph found between train and val\")\n",
    "                cnt += 1\n",
    "                break\n",
    "    print(\"Number of leaks in Val from train: \",cnt)\n",
    "\n",
    "    cnt = 0\n",
    "    for test_g in tqdm(test_nx):\n",
    "        for train_g in train_nx:\n",
    "            if nx.is_isomorphic(train_g, test_g, node_match=node_match_fun):\n",
    "                #print(\"Isomorphic graph found between train and val\")\n",
    "                cnt += 1\n",
    "                break\n",
    "    print(\"Number of leaks in test from train: \",cnt)\n",
    "\n",
    "def generate_uniqe_graphs(graphs, DATASET, node_labeled = False, node_is_multihot = False, max_unique_cnt = None, check = False):\n",
    "    \"\"\"\n",
    "        graphs: list of torch_geometric.data.Data objects\n",
    "            data[i].x: Node features of graph i\n",
    "        DATASET: Name of the dataset\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if not node_labeled and node_is_multihot:\n",
    "        print(\"ERROR: Node cannot be multihot and not labeled at the same time\")\n",
    "        return\n",
    "    \n",
    "    data_path = dest_folder + DATASET + '/'\n",
    "    if not os.path.isdir(data_path):\n",
    "        os.mkdir(data_path)\n",
    "\n",
    "    print(\"Total number of graphs: \", len(graphs))\n",
    "    print(\"Selecting Small Graphs...\")\n",
    "    graphs = list(filter(lambda x: x.num_nodes <= max_num_nodes, graphs))\n",
    "    print(f\"Graphs with at most {max_num_nodes} nodes: {len(graphs)}\")\n",
    "\n",
    "    if not node_labeled:\n",
    "        graphs = list(map(set_x, graphs))\n",
    "    \n",
    "    nx_graphs = list(map(functools.partial(to_networkx, to_undirected=True, node_attrs = ['x']), graphs))\n",
    "\n",
    "    if node_is_multihot:\n",
    "        node_match_func = node_match_multi_hot\n",
    "    else:\n",
    "        node_match_func = node_match\n",
    "\n",
    "    unique_nx_graphs = get_unique_graphs_using_nx(nx_graphs, node_match_func = node_match_func, max_unique_cnt = max_unique_cnt)\n",
    "    \n",
    "    sizes = list(map(lambda x: x.number_of_nodes(), unique_nx_graphs))\n",
    "    print(\"Maximum number of nodes in the dataset: \", max(sizes))\n",
    "    split_and_dump_graphs(unique_nx_graphs, data_path, DATASET)\n",
    "    if check:\n",
    "        check_leakage(data_path, full_check = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'AIDS'\n",
    "data = TUDataset(root=\"/tmp/\", name=DATASET)\n",
    "node_labeled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of graphs:  2000\n",
      "Selecting Small Graphs...\n",
      "Graphs with at most 20 nodes: 1666\n",
      "Filtering isomorphic graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 224/1665 [00:00<00:02, 554.79it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1665/1665 [00:09<00:00, 174.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Unique graphs: 911\n",
      "Maximum number of nodes in the dataset:  20\n",
      "Splitting and dumping graphs...\n",
      "Train: 546, Val: 182, Test: 183\n",
      "sample: Data(edge_index=[2, 20], x=[11, 1])\n",
      "saved AIDS into ./data_wo_node_attr/AIDS/train.pt\n",
      "saved AIDS into ./data_wo_node_attr/AIDS/val.pt\n",
      "saved AIDS into ./data_wo_node_attr/AIDS/test.pt\n"
     ]
    }
   ],
   "source": [
    "generate_uniqe_graphs(data, DATASET, node_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for leakage...\n",
      "loading saved splits from  ./data_wo_node_attr//AIDS/\n",
      "Number of graphs in train:  546  Val:  182  Test:  183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 182/182 [00:01<00:00, 134.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaks in Val from train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [00:01<00:00, 132.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaks in test from train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "check_leakage(dest_folder + '/AIDS/', full_check = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 20], x=[11, 1])\n"
     ]
    }
   ],
   "source": [
    "dummy = torch.load(dest_folder + '/AIDS/train.pt')\n",
    "print(dummy[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINUX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  torch_geometric.datasets.ged_dataset import GEDDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'LINUX'\n",
    "\n",
    "train_data = GEDDataset('/tmp/', name = \"LINUX\")\n",
    "test_data = GEDDataset('/tmp/', name = \"LINUX\", train = False)\n",
    "data = train_data + test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 18], i=[1], num_nodes=8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labeled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of graphs:  1000\n",
      "Selecting Small Graphs...\n",
      "Graphs with at most 20 nodes: 1000\n",
      "Filtering isomorphic graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 999/999 [00:00<00:00, 1937.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Unique graphs: 89\n",
      "Maximum number of nodes in the dataset:  10\n",
      "Splitting and dumping graphs...\n",
      "Train: 53, Val: 17, Test: 19\n",
      "sample: Data(edge_index=[2, 16], x=[9, 1])\n",
      "saved LINUX into ./data_wo_node_attr/LINUX/train.pt\n",
      "saved LINUX into ./data_wo_node_attr/LINUX/val.pt\n",
      "saved LINUX into ./data_wo_node_attr/LINUX/test.pt\n"
     ]
    }
   ],
   "source": [
    "generate_uniqe_graphs(data, DATASET, node_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for leakage...\n",
      "loading saved splits from  ./data_wo_node_attr//LINUX/\n",
      "Number of graphs in train:  53  Val:  17  Test:  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 1142.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaks in Val from train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 1171.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaks in test from train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "check_leakage(dest_folder +'/LINUX/', full_check = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 16], x=[9, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = torch.load(dest_folder +'/LINUX/train.pt')\n",
    "dummy[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OGBG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.graphproppred import PygGraphPropPredDataset\n",
    "from torch_geometric.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ogbg-code2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'ogbg-code2'\n",
    "data = PygGraphPropPredDataset(name = DATASET) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 243], x=[244, 2], node_is_attributed=[244, 1], node_dfs_order=[244, 1], node_depth=[244, 1], y=[1], num_nodes=244)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 452741/452741 [00:53<00:00, 8459.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number valid graphs in the dataset:  404\n"
     ]
    }
   ],
   "source": [
    "# For OGBA-CODE2 Label adjustment\n",
    "\n",
    "node_labeled = False\n",
    "\n",
    "valid_graphs = []\n",
    "for g in tqdm(data):\n",
    "    if (g.num_nodes <= 20):\n",
    "        labels = g.x[:, 0]\n",
    "        g.x = torch.nn.functional.one_hot(labels, 97).float()\n",
    "        rev1 = torch.stack((g.edge_index[1], g.edge_index[0]), 0)\n",
    "        g.edge_index = torch.cat((g.edge_index, rev1), -1)\n",
    "        valid_graphs.append(g)\n",
    "data = valid_graphs\n",
    "print(\"Total number valid graphs in the dataset: \", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of graphs:  404\n",
      "Selecting Small Graphs...\n",
      "Graphs with at most 20 nodes: 404\n",
      "Filtering isomorphic graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 310/403 [00:15<00:06, 13.85it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout for graph 269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 403/403 [00:30<00:00, 13.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout for graph 369\n",
      "Total number of Unique graphs: 128\n",
      "Maximum number of nodes in the dataset:  20\n",
      "Splitting and dumping graphs...\n",
      "Train: 76, Val: 25, Test: 27\n",
      "sample: Data(edge_index=[2, 38], x=[20, 1])\n",
      "saved ogbg-code2 into ./data_wo_node_attr/ogbg-code2/train.pt\n",
      "saved ogbg-code2 into ./data_wo_node_attr/ogbg-code2/val.pt\n",
      "saved ogbg-code2 into ./data_wo_node_attr/ogbg-code2/test.pt\n",
      "CPU times: user 31.5 s, sys: 1.19 s, total: 32.7 s\n",
      "Wall time: 31.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generate_uniqe_graphs(data, DATASET, node_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for leakage...\n",
      "loading saved splits from  ./data_wo_node_attr//ogbg-code2\n",
      "Number of graphs in train:  76  Val:  25  Test:  27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 538.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaks in Val from train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 664.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaks in test from train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "check_leakage(dest_folder + '/ogbg-code2', full_check = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 38], x=[20, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = torch.load(dest_folder + '/ogbg-code2/train.pt')\n",
    "dummy[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ogbg-molhiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'ogbg-molhiv'\n",
    "data = PygGraphPropPredDataset(name = DATASET) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41127\n",
      "Data(edge_index=[2, 40], edge_attr=[40, 3], x=[19, 9], y=[1, 1], num_nodes=19)\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labeled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_graphs = []\n",
    "cnt = 0\n",
    "for g in data:\n",
    "    if (g.num_nodes <= 50):\n",
    "        labels = g.x[:, 0]\n",
    "        g.x = torch.nn.functional.one_hot(labels, 119).float()\n",
    "        new_graphs.append(g)\n",
    "data = new_graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39650"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of graphs:  39650\n",
      "Selecting Small Graphs...\n",
      "Graphs with at most 20 nodes: 14923\n",
      "Filtering isomorphic graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1204/14922 [00:06<01:13, 185.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Unique graphs: 1000\n",
      "Maximum number of nodes in the dataset:  20\n",
      "Splitting and dumping graphs...\n",
      "Train: 600, Val: 200, Test: 200\n",
      "sample: Data(edge_index=[2, 34], x=[16, 1])\n",
      "saved ogbg-molhiv into ./data_wo_node_attr/ogbg-molhiv/train.pt\n",
      "saved ogbg-molhiv into ./data_wo_node_attr/ogbg-molhiv/val.pt\n",
      "saved ogbg-molhiv into ./data_wo_node_attr/ogbg-molhiv/test.pt\n"
     ]
    }
   ],
   "source": [
    "generate_uniqe_graphs(data, DATASET, node_labeled, max_unique_cnt = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 34], x=[16, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = torch.load(dest_folder + '/ogbg-molhiv/train.pt')\n",
    "dummy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for leakage...\n",
      "loading saved splits from  ./data_wo_node_attr//ogbg-molhiv\n",
      "Number of graphs in train:  600  Val:  200  Test:  200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 158.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaks in Val from train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 162.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaks in test from train:  0\n"
     ]
    }
   ],
   "source": [
    "check_leakage(dest_folder + '/ogbg-molhiv', full_check = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ogbg-molpcba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'ogbg-molpcba'\n",
    "data = PygGraphPropPredDataset(name = DATASET) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437929\n",
      "Data(edge_index=[2, 44], edge_attr=[44, 3], x=[20, 9], y=[1, 128], num_nodes=20)\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labeled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80355"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_graphs = []\n",
    "cnt = 0\n",
    "for g in data:\n",
    "    if (g.num_nodes <= 20):\n",
    "        labels = g.x[:, 0]\n",
    "        g.x = torch.nn.functional.one_hot(labels, 119).float()\n",
    "        new_graphs.append(g)\n",
    "data = new_graphs\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of graphs:  80355\n",
      "Selecting Small Graphs...\n",
      "Graphs with at most 20 nodes: 80355\n",
      "Filtering isomorphic graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1035/80354 [00:08<10:46, 122.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Unique graphs: 1000\n",
      "Maximum number of nodes in the dataset:  20\n",
      "Splitting and dumping graphs...\n",
      "Train: 600, Val: 200, Test: 200\n",
      "sample: Data(edge_index=[2, 36], x=[17, 1])\n",
      "saved ogbg-molpcba into ./data_wo_node_attr/ogbg-molpcba/train.pt\n",
      "saved ogbg-molpcba into ./data_wo_node_attr/ogbg-molpcba/val.pt\n",
      "saved ogbg-molpcba into ./data_wo_node_attr/ogbg-molpcba/test.pt\n"
     ]
    }
   ],
   "source": [
    "generate_uniqe_graphs(data, DATASET, node_labeled, max_unique_cnt = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 36], x=[17, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = torch.load(dest_folder + '/ogbg-molpcba/train.pt')\n",
    "dummy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for leakage...\n",
      "loading saved splits from  ./data_wo_node_attr//ogbg-molpcba\n",
      "Number of graphs in train:  600  Val:  200  Test:  200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 104.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaks in Val from train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 109.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaks in test from train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "check_leakage(dest_folder + '/ogbg-molpcba', full_check = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutagenicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'Mutagenicity'\n",
    "data = TUDataset(root = '/tmp/', name = DATASET) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4337\n",
      "Data(edge_index=[2, 32], x=[16, 14], edge_attr=[32, 3], y=[1])\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "count = torch.sum(data[6].x, dim=-1)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labeled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of graphs:  4337\n",
      "Selecting Small Graphs...\n",
      "Graphs with at most 20 nodes: 1287\n",
      "Filtering isomorphic graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1286/1286 [00:09<00:00, 140.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Unique graphs: 729\n",
      "Maximum number of nodes in the dataset:  20\n",
      "Splitting and dumping graphs...\n",
      "Train: 437, Val: 145, Test: 147\n",
      "sample: Data(edge_index=[2, 16], x=[9, 1])\n",
      "saved Mutagenicity into ./data_wo_node_attr/Mutagenicity/train.pt\n",
      "saved Mutagenicity into ./data_wo_node_attr/Mutagenicity/val.pt\n",
      "saved Mutagenicity into ./data_wo_node_attr/Mutagenicity/test.pt\n"
     ]
    }
   ],
   "source": [
    "generate_uniqe_graphs(data, DATASET, node_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 16], x=[9, 1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = torch.load(dest_folder + '/Mutagenicity/train.pt')\n",
    "dummy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for leakage...\n",
      "loading saved splits from  ./data_wo_node_attr//Mutagenicity\n",
      "Number of graphs in train:  437  Val:  145  Test:  147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145/145 [00:01<00:00, 111.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaks in Val from train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:01<00:00, 103.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaks in test from train:  0\n"
     ]
    }
   ],
   "source": [
    "check_leakage(dest_folder + '/Mutagenicity', full_check = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yeast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'Yeast'\n",
    "data = TUDataset(root = '/tmp/', name = DATASET) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79601\n",
      "Data(edge_index=[2, 32], x=[18, 74], edge_attr=[32, 3], y=[1])\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "count = torch.sum(data[1].x, dim=-1)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labeled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of graphs:  79601\n",
      "Selecting Small Graphs...\n",
      "Graphs with at most 20 nodes: 41724\n",
      "Filtering isomorphic graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1115/41723 [00:08<05:19, 127.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Unique graphs: 1000\n",
      "Maximum number of nodes in the dataset:  20\n",
      "Splitting and dumping graphs...\n",
      "Train: 600, Val: 200, Test: 200\n",
      "sample: Data(edge_index=[2, 36], x=[17, 1])\n",
      "saved Yeast into ./data_wo_node_attr/Yeast/train.pt\n",
      "saved Yeast into ./data_wo_node_attr/Yeast/val.pt\n",
      "saved Yeast into ./data_wo_node_attr/Yeast/test.pt\n"
     ]
    }
   ],
   "source": [
    "generate_uniqe_graphs(data, DATASET, node_labeled, max_unique_cnt=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 12], x=[6, 1])\n"
     ]
    }
   ],
   "source": [
    "dummy2 = torch.load(dest_folder + '/Yeast/train.pt')\n",
    "print(dummy2[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for leakage...\n",
      "loading saved splits from  ./data_wo_node_attr//Yeast\n",
      "Number of graphs in train:  600  Val:  200  Test:  200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 112.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaks in Val from train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 114.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaks in test from train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "check_leakage(dest_folder + '/Yeast', full_check = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GED",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
